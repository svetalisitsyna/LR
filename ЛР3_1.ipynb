{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# 1\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=784, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n",
        "_, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Точность - {test_acc*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V26NtW-WGPN-",
        "outputId": "68acfdb8-3231-4df9-9fc3-03c3998a5c52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 1.0049 - val_accuracy: 0.8212 - val_loss: 0.5022\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4839 - val_accuracy: 0.8425 - val_loss: 0.4476\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4417 - val_accuracy: 0.8470 - val_loss: 0.4347\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.4162 - val_accuracy: 0.8452 - val_loss: 0.4455\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.4126 - val_accuracy: 0.8495 - val_loss: 0.4258\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.4008 - val_accuracy: 0.8465 - val_loss: 0.4244\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3933 - val_accuracy: 0.8508 - val_loss: 0.4123\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3960 - val_accuracy: 0.8525 - val_loss: 0.4063\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.3846 - val_accuracy: 0.8545 - val_loss: 0.4174\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.3829 - val_accuracy: 0.8503 - val_loss: 0.4331\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.4495\n",
            "Точность - 83.92000198364258%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense( 50, input_dim=784, activation='relu'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "metrics=['accuracy'])\n",
        "model2.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n",
        "_, test_acc2 = model2.evaluate(x_test, y_test)\n",
        "print(f\"Точность - {test_acc2*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ZWQEycGRGy",
        "outputId": "7802d589-ef46-4e08-f1c0-9afb2ad6e126"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7596 - loss: 0.7077 - val_accuracy: 0.8418 - val_loss: 0.4398\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 0.4123 - val_accuracy: 0.8585 - val_loss: 0.3930\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.3655 - val_accuracy: 0.8633 - val_loss: 0.3879\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3428 - val_accuracy: 0.8673 - val_loss: 0.3614\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.3295 - val_accuracy: 0.8720 - val_loss: 0.3607\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.3092 - val_accuracy: 0.8780 - val_loss: 0.3425\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.2964 - val_accuracy: 0.8777 - val_loss: 0.3399\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2920 - val_accuracy: 0.8768 - val_loss: 0.3552\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.2818 - val_accuracy: 0.8743 - val_loss: 0.3543\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2717 - val_accuracy: 0.8772 - val_loss: 0.3409\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3571\n",
            "Точность - 87.34999895095825%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(50, input_dim=784, activation='relu'))\n",
        "model3.add(Dense(50, activation='relu'))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "metrics=['accuracy'])\n",
        "model3.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n",
        "_, test_acc3 = model3.evaluate(x_test, y_test)\n",
        "print(f\"Точность - {test_acc3*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6agEg_vGZIp",
        "outputId": "9a53a49d-e617-4a79-8f54-c9825a3d9251"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.7051 - val_accuracy: 0.8483 - val_loss: 0.4193\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.4010 - val_accuracy: 0.8550 - val_loss: 0.3964\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.3651 - val_accuracy: 0.8647 - val_loss: 0.3764\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.3368 - val_accuracy: 0.8712 - val_loss: 0.3716\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.3084 - val_accuracy: 0.8783 - val_loss: 0.3354\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.3013 - val_accuracy: 0.8647 - val_loss: 0.3924\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2910 - val_accuracy: 0.8772 - val_loss: 0.3598\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.2776 - val_accuracy: 0.8810 - val_loss: 0.3481\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2681 - val_accuracy: 0.8788 - val_loss: 0.3550\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.2585 - val_accuracy: 0.8798 - val_loss: 0.3586\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.3716\n",
            "Точность - 86.91999912261963%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train[:,:,:,np.newaxis] / 255.0\n",
        "x_test = x_test[:,:,:,np.newaxis] / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Conv2D(filters=64, kernel_size=2, padding='same',\n",
        "activation='relu', input_shape=(28,28, 1)))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(10, activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "metrics=['accuracy'])\n",
        "model4.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n",
        "_, test_acc4 = model4.evaluate(x_test, y_test)\n",
        "print(f\"Точность - {test_acc4*100}%\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Kk27YbGbWi",
        "outputId": "c543a90c-089d-4371-e92c-42708e910f05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 26ms/step - accuracy: 0.7987 - loss: 0.5754 - val_accuracy: 0.8757 - val_loss: 0.3383\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.8862 - loss: 0.3250 - val_accuracy: 0.8965 - val_loss: 0.2989\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9030 - loss: 0.2776 - val_accuracy: 0.8770 - val_loss: 0.3339\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.9093 - loss: 0.2520 - val_accuracy: 0.8892 - val_loss: 0.3030\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.9134 - loss: 0.2445 - val_accuracy: 0.9008 - val_loss: 0.2756\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9179 - loss: 0.2280 - val_accuracy: 0.9020 - val_loss: 0.2785\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9240 - loss: 0.2138 - val_accuracy: 0.9038 - val_loss: 0.2744\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9260 - loss: 0.2056 - val_accuracy: 0.9053 - val_loss: 0.2708\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9326 - loss: 0.1909 - val_accuracy: 0.9012 - val_loss: 0.2833\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9348 - loss: 0.1842 - val_accuracy: 0.9033 - val_loss: 0.2738\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8980 - loss: 0.2924\n",
            "Точность - 89.56999778747559%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Архитектура 2-3-3\n",
        "# Скорость обучения 0.25\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "# Загрузка и подготовка MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 28*28).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], 28*28).astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Инициализируем веса для каждого слоя\n",
        "weights_input_hidden = np.random.uniform(-0.3, 0.3, (28*28, 3))  # 784 -> 3\n",
        "weights_hidden_hidden = np.random.uniform(-0.3, 0.3, (3, 3))     # 3 -> 3\n",
        "weights_hidden_output = np.random.uniform(-0.3, 0.3, (3, 10))    # 3 -> 10\n",
        "\n",
        "# Строим модель\n",
        "model__new = Sequential()\n",
        "model__new.add(Dense(3, kernel_initializer=Constant(weights_input_hidden), input_dim=28*28, activation='sigmoid'))\n",
        "model__new.add(Dense(3, kernel_initializer=Constant(weights_hidden_hidden), activation='sigmoid'))\n",
        "model__new.add(Dense(10, kernel_initializer=Constant(weights_hidden_output), activation='sigmoid'))\n",
        "\n",
        "# Компиляция модели\n",
        "model__new.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.25), metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model__new.fit(x_train, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "# Оценка точности\n",
        "_, test_acc = model__new.evaluate(x_test, y_test)\n",
        "print(test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BuVvvG7Lm_U",
        "outputId": "fad478b8-357e-4550-cb9d-567e8e7b2046"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2324 - loss: 1.9374 - val_accuracy: 0.2602 - val_loss: 1.7229\n",
            "Epoch 2/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2879 - loss: 1.7152 - val_accuracy: 0.3252 - val_loss: 1.6630\n",
            "Epoch 3/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3328 - loss: 1.6422 - val_accuracy: 0.2493 - val_loss: 1.6743\n",
            "Epoch 4/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3345 - loss: 1.6309 - val_accuracy: 0.3280 - val_loss: 1.5484\n",
            "Epoch 5/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3351 - loss: 1.6214 - val_accuracy: 0.3530 - val_loss: 1.5214\n",
            "Epoch 6/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3546 - loss: 1.5582 - val_accuracy: 0.3723 - val_loss: 1.4603\n",
            "Epoch 7/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3574 - loss: 1.5432 - val_accuracy: 0.3877 - val_loss: 1.4713\n",
            "Epoch 8/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3707 - loss: 1.5369 - val_accuracy: 0.3675 - val_loss: 1.4206\n",
            "Epoch 9/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3648 - loss: 1.5083 - val_accuracy: 0.3868 - val_loss: 1.4427\n",
            "Epoch 10/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.3653 - loss: 1.4924 - val_accuracy: 0.3315 - val_loss: 1.5519\n",
            "Epoch 11/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3496 - loss: 1.5306 - val_accuracy: 0.3492 - val_loss: 1.4392\n",
            "Epoch 12/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3658 - loss: 1.5179 - val_accuracy: 0.3068 - val_loss: 1.6258\n",
            "Epoch 13/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3457 - loss: 1.5699 - val_accuracy: 0.3583 - val_loss: 1.4402\n",
            "Epoch 14/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.3749 - loss: 1.4758 - val_accuracy: 0.3547 - val_loss: 1.4389\n",
            "Epoch 15/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3702 - loss: 1.4737 - val_accuracy: 0.3695 - val_loss: 1.3976\n",
            "Epoch 16/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3712 - loss: 1.4649 - val_accuracy: 0.3632 - val_loss: 1.5162\n",
            "Epoch 17/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3660 - loss: 1.5227 - val_accuracy: 0.3738 - val_loss: 1.4214\n",
            "Epoch 18/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.3746 - loss: 1.4710 - val_accuracy: 0.3782 - val_loss: 1.4050\n",
            "Epoch 19/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3746 - loss: 1.4631 - val_accuracy: 0.3600 - val_loss: 1.5501\n",
            "Epoch 20/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3688 - loss: 1.5004 - val_accuracy: 0.3747 - val_loss: 1.3909\n",
            "Epoch 21/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3711 - loss: 1.4494 - val_accuracy: 0.3462 - val_loss: 1.4345\n",
            "Epoch 22/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3678 - loss: 1.4534 - val_accuracy: 0.3792 - val_loss: 1.3959\n",
            "Epoch 23/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3724 - loss: 1.4708 - val_accuracy: 0.3553 - val_loss: 1.4595\n",
            "Epoch 24/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3719 - loss: 1.4607 - val_accuracy: 0.3723 - val_loss: 1.3849\n",
            "Epoch 25/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3564 - loss: 1.5171 - val_accuracy: 0.3880 - val_loss: 1.3812\n",
            "Epoch 26/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3725 - loss: 1.4499 - val_accuracy: 0.3710 - val_loss: 1.3669\n",
            "Epoch 27/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.3753 - loss: 1.4500 - val_accuracy: 0.3940 - val_loss: 1.3984\n",
            "Epoch 28/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3737 - loss: 1.4548 - val_accuracy: 0.3788 - val_loss: 1.4601\n",
            "Epoch 29/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3739 - loss: 1.4541 - val_accuracy: 0.3867 - val_loss: 1.4042\n",
            "Epoch 30/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3654 - loss: 1.4698 - val_accuracy: 0.3898 - val_loss: 1.4162\n",
            "Epoch 31/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.3712 - loss: 1.4535 - val_accuracy: 0.3723 - val_loss: 1.4150\n",
            "Epoch 32/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3694 - loss: 1.4530 - val_accuracy: 0.3677 - val_loss: 1.4341\n",
            "Epoch 33/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3757 - loss: 1.4592 - val_accuracy: 0.3873 - val_loss: 1.3742\n",
            "Epoch 34/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3759 - loss: 1.4196 - val_accuracy: 0.3748 - val_loss: 1.3922\n",
            "Epoch 35/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3706 - loss: 1.4373 - val_accuracy: 0.3683 - val_loss: 1.3700\n",
            "Epoch 36/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3633 - loss: 1.4477 - val_accuracy: 0.3747 - val_loss: 1.4268\n",
            "Epoch 37/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3650 - loss: 1.4867 - val_accuracy: 0.3668 - val_loss: 1.4166\n",
            "Epoch 38/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3706 - loss: 1.4563 - val_accuracy: 0.3577 - val_loss: 1.4097\n",
            "Epoch 39/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3700 - loss: 1.4445 - val_accuracy: 0.3703 - val_loss: 1.4048\n",
            "Epoch 40/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3712 - loss: 1.4295 - val_accuracy: 0.3703 - val_loss: 1.3707\n",
            "Epoch 41/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3712 - loss: 1.4272 - val_accuracy: 0.3685 - val_loss: 1.3743\n",
            "Epoch 42/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3699 - loss: 1.4343 - val_accuracy: 0.3763 - val_loss: 1.4171\n",
            "Epoch 43/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3632 - loss: 1.4492 - val_accuracy: 0.3625 - val_loss: 1.3654\n",
            "Epoch 44/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3727 - loss: 1.4436 - val_accuracy: 0.3692 - val_loss: 1.3719\n",
            "Epoch 45/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3751 - loss: 1.4156 - val_accuracy: 0.3573 - val_loss: 1.3834\n",
            "Epoch 46/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.3795 - loss: 1.4222 - val_accuracy: 0.3677 - val_loss: 1.3666\n",
            "Epoch 47/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3747 - loss: 1.4284 - val_accuracy: 0.3728 - val_loss: 1.3644\n",
            "Epoch 48/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3735 - loss: 1.4374 - val_accuracy: 0.3725 - val_loss: 1.3634\n",
            "Epoch 49/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3712 - loss: 1.4338 - val_accuracy: 0.3833 - val_loss: 1.4030\n",
            "Epoch 50/50\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3693 - loss: 1.4348 - val_accuracy: 0.3797 - val_loss: 1.3453\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3774 - loss: 1.3948\n",
            "0.374099999666214\n"
          ]
        }
      ]
    }
  ]
}